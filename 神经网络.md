神经网络在数学编程实现本质上是函数嵌套(线性非线性)组合，模拟任意复杂的函数  
一个神经网络本质上是模型(层连接激活函数超参数搭建)、参数wb  
神经网络学习本质上参数迭代更新  

网络、定义损失函数
基于梯度的优化器学习

神经网络  
>>除去神经网络结构的细节信息不谈，整个神经网络模型其实是在构造一个参数数量巨大的函数（百万级，甚至更多），不妨记为f(x)，通过设定目标函数，可以训练神经网络逼近非常复杂的真实函数g(x)。训练的关键是要设定目标函数，反馈给神经网络当前的表现如何。训练过程就是不断减小目标函数值的过程。
>>>函数(模拟任意复杂、结构等超参)+待定参数  
>>>损失函数+优化器  



sigmoid是神经元激活函数  
softmax是函数，softmax层，全连接，输入和输出大小一样，应用softmax
