1.分类/回归任务<br>

2.liner regression/logistics regression
>> liner=wx+b / logistics=liner+sigmoid=sigmoid(wx+b) <br>
>> 预测值在连续空间/预测值在0-1连续空间<br>
>> 将∞预测值压缩到0-1之间，适合表示概率问题

3.激活函数
>>1.增加非线性/增加神经网络函数非线性拟合能力 2.生物角度模拟大脑  
>>2+2 公式/图像/适用特征  
>>>sigmoid 将数值映射到0-1之间  
>>>tanh 将数值映射到-1-1之间  
>>>relu

4.矩阵相乘
>>element-wise:对应位置元素相乘<br>
>>matmul:标准矩阵乘法


5.KL散度 https://www.jianshu.com/p/43318a3dc715


6.核函数
>>支持向量机通过某非线性变换 φ( x) ，将输入空间映射到高维特征空间(特征空间的维数可能非常高)。  
>>如果支持向量机的求解只用到内积运算，而在低维输入空间又存在某个函数 K(x, x′) ，它恰好等于在高维空间中这个内积，即K( x, x′) =<φ( x) ⋅φ( x′) > 。  
>>那么支持向量机就不用计算复杂的非线性变换，而由这个函数 K(x, x′) 直接得到非线性变换的内积，使大大简化了计算。这样的函数 K(x, x′) 称为核函数。  

思路：  
输入空间->非线性映射函数φ->高维特征空间  
在高维空间将非线性问题转换为线性问题    
进一步：
核函数不需要显式的定义特征空间和映射函数，只是用来计算映射到高维空间之后的内积的一种简便方法
核技巧：巧妙的使用 核函数+线性分类学习方法 解决非线性问题
>>>核函数的使用：依赖经验直觉直接选择核函数，核函数的有效性需要实验验证。  
>>>很多使用者都是盲目地试验各种核函数+扫描其中的参数，选择效果最好的。至于什么样的核函数适用于什么样的问题，大多数人都不懂。  

